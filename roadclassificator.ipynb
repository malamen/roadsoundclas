{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sound Road Classificator\n",
    "## Algorythm to classification of sound using RNN\n",
    "This algorythom is based in Tensorflow and Librosa\n",
    "\n",
    "## System and Libraries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Libraries and Language:\n",
    "- Python 3.6\n",
    "- Tensorflow 1.2.1\n",
    "- numpy 1.13.1\n",
    "- Librosa 0.5.1\n",
    "- Matplotlib 1.5.3\n",
    "\n",
    "Desktop\n",
    "- MacBook Pro mid 2012\n",
    "    - Intel i5 Dual-Core, 2,5 Ghz (4ta Gen)\n",
    "    - 16 GB RAM DDR3 1600mhz\n",
    "Server\n",
    "-Azure F16s Ubuntu server 16.04\n",
    "    - Intel Xeon 16-Cores ,2.4 Ghz\n",
    "    - 32 GB RAM  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "### Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training variables\n",
    "\n",
    "For complete training on server we used 10000 iterations(training_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_iters = 500\n",
    "#training_iters = 10000\n",
    "batch_size = 50\n",
    "display_step = 200\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 50 \n",
    "n_steps = 50\n",
    "n_hidden = 300\n",
    "n_classes = 2 \n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_input, n_steps])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "weight = tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += (window_size / 2)\n",
    "\n",
    "def extract_features(parent_dir,sub_dirs,file_ext=\"*.flac\",bands = 50, frames = 100):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    mfccs = []\n",
    "    labels = []\n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            sound_clip,s = librosa.load(fn)\n",
    "            label = fn.split('/')[2].split('-')[1]\n",
    "            for (start,end) in windows(sound_clip,window_size):\n",
    "                tmp_clip = sound_clip[int(start):int(end)]\n",
    "                if len(tmp_clip) == window_size:\n",
    "                    signal = tmp_clip\n",
    "                    mfcc = librosa.feature.mfcc(y=signal, sr=s, n_mfcc = bands).T.flatten()[:, np.newaxis].T\n",
    "                    mfccs.append(mfcc)\n",
    "                    labels.append(label)         \n",
    "    features = np.asarray(mfccs).reshape(len(mfccs),bands,frames)\n",
    "    return np.array(features), np.array(labels,dtype = np.int)\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parent_dir = 'trainset'\n",
    "tr_sub_dirs = ['blacktop','cobblestone']\n",
    "tr_features,tr_labels = extract_features(parent_dir,tr_sub_dirs)\n",
    "tr_labels = one_hot_encode(tr_labels)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(tr_features[10], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC Blacktop')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(tr_features[len(tr_features)-10], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC Cobblestone')\n",
    "plt.tight_layout()\n",
    "\n",
    "s = np.arange(tr_features.shape[0])\n",
    "np.random.shuffle(s)\n",
    "tr_features = tr_features[s]\n",
    "tr_labels = tr_labels[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Mel-frequency cepstral coefficients graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x, weight, bias):\n",
    "    cell = rnn_cell.LSTMCell(n_hidden,state_is_tuple = True)\n",
    "    cell = rnn_cell.MultiRNNCell([cell])\n",
    "    output, state = tf.nn.dynamic_rnn(cell, x, dtype = tf.float32)\n",
    "    output = tf.transpose(output, [1, 0, 2])\n",
    "    last = tf.gather(output, int(output.get_shape()[0]) - 1)\n",
    "    return tf.nn.softmax(tf.matmul(last, weight) + bias)\n",
    "\n",
    "prediction = RNN(x, weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "loss_f = -tf.reduce_sum(y * tf.log(prediction))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_f)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def train_model(output='model/small/model_small.ckt'):  \n",
    "    with tf.Session() as session:\n",
    "        session.run(init)\n",
    "        \n",
    "        for itr in range(training_iters):    \n",
    "            offset = (itr * batch_size) % (tr_labels.shape[0] - batch_size)\n",
    "            batch_x = tr_features[offset:(offset + batch_size), :, :]\n",
    "            batch_y = tr_labels[offset:(offset + batch_size), :]\n",
    "            _, c = session.run([optimizer, loss_f],feed_dict={x: batch_x, y : batch_y})\n",
    "                \n",
    "            if itr % display_step == 0:\n",
    "                # Calculate batch accuracy\n",
    "                acc = session.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "                # Calculate batch loss\n",
    "                loss = session.run(loss_f, feed_dict={x: batch_x, y: batch_y})\n",
    "                print (\"Iter \" + str(itr) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "        \n",
    "        #print('Test accuracy: ',round(session.run(accuracy, feed_dict={x: tr_features, y: tr_labels}) , 3))\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(session, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model('model/small/model_small_2.ckt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shape tensors\n",
    "x = tf.placeholder(\"float\", [None, n_input, n_steps])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "weight = tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = RNN(x, weight, bias)    \n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_test(input_test ,bands = n_input, frames = n_steps):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    mfccs = []\n",
    "    labels = []\n",
    "    sound_clip,s = librosa.load(input_test)\n",
    "\n",
    "    for (start,end) in windows(sound_clip,window_size):\n",
    "        tmp_clip = sound_clip[int(start):int(end)]\n",
    "        if len(tmp_clip) == window_size:\n",
    "            signal = tmp_clip\n",
    "            mfcc = librosa.feature.mfcc(y=signal, sr=s, n_mfcc = bands).T.flatten()[:, np.newaxis].T\n",
    "            mfccs.append(mfcc)\n",
    "\n",
    "    features = np.asarray(mfccs).reshape(len(mfccs),bands,frames)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict Function\n",
    "def predict(sample_path=\"trainset/blacktop/blacktop-0-.flac\", model_path=\"./model/small/model_small.ckt.meta\"):\n",
    "\n",
    "    saver = tf.train.import_meta_graph(model_path)\n",
    "    ts_features = extract_features_test(sample_path)\n",
    "\n",
    "    type0 = []\n",
    "    type1 = []\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "       # Initialize variables\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Restore model weights from previously saved model\n",
    "        offset = 0\n",
    "        while offset<len(ts_features):\n",
    "            batch_x = ts_features[offset:(offset + batch_size), :, :]\n",
    "            feed_dict = {x: batch_x}\n",
    "            classification = sess.run(tf.argmax(prediction,1),feed_dict)\n",
    "            tmp1 = 0.\n",
    "            for ii in classification:\n",
    "                if ii == 1:\n",
    "                    tmp1 = tmp1 + 1;\n",
    "            tmptmp = float(tmp1)/len(classification)\n",
    "            type0.append(1.-tmptmp)\n",
    "            type1.append(tmptmp)\n",
    "            offset= offset + batch_size\n",
    "    return type0, type1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
